---
permalink: /
title: "AI Researcher"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm an AI researcher currently focusing on AI Safety and developing safe super-intelligence. Im also a Political Scientist, and i'm deeply concerned about how to safeguard human institutions and society from the impending intelligence explosion. 

My research focuses on AI safety and safe super-intelligence. Below are some of the main areas I am interested in:

1. Superalignment
2. Scalable Oversight
3. Societal Impact

Broadly, I am interested in exploring how we can develop AI systems that are not only highly capable, but also deeply aligned with human values and the wellbeing of society. This encompasses the technical challenges of 'aligning' superintelligent AI systems, as well as the critical questions of how we can ensure the societal and institutional impacts of advanced AI are positive and beneficial.

*Email:* tom@superailab.org

[Google Scholar Page](https://scholar.google.com/citations?user=ZUEwQFkAAAAJ=en)

## News
* 2024 - New paper out! "The Ministry of Artificial Intelligence: A Catalyst For National AI Ecosystems and Global Cooperation in the Age of Superintelligence" [[ResearchGate]](https://www.researchgate.net/publication/383145922_The_Ministry_of_Artificial_Intelligence_A_Catalyst_For_National_AI_Ecosystems_and_Global_Cooperation_in_the_Age_of_Superintelligence)

For more info
------
More info about configuring Academic Pages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
